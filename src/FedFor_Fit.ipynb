{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, random, argparse, ast, copy\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Spambase.split_data import split_data_equal\n",
    "from utils.aggregate_functions import FederatedForest\n",
    "from utils.DecisionTree import DecisionTree\n",
    "from utils.nash1 import find_nash_equilibria_v2\n",
    "from utils.evaluate_coalitions_new import evaluate_coalitions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Nash_lottery import find_nash_equilibria_lottery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuGaDB Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def payoff_10(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.9566\n",
    "        + 0.0324 * mu\n",
    "        + 0.0134 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_20(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.8198\n",
    "        + 0.0048 * mu\n",
    "        - 0.0042 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_30(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.6367\n",
    "        + 0.0218 * mu\n",
    "        - 0.0011 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_40(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.4733\n",
    "        + 0.0425 * mu\n",
    "        + 0.0044 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_50(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.3218\n",
    "        + 0.0702 * mu\n",
    "        + 0.0204 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_60(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.1931\n",
    "        + 0.0930 * mu\n",
    "        + 0.0030 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_70(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        1.0139\n",
    "        + 0.1545 * mu\n",
    "        + 0.0026 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_80(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        0.8174\n",
    "        + 0.1995 * mu\n",
    "        + 0.0159 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_90(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        0.6717\n",
    "        + 0.2508 * mu\n",
    "        + 0.0197 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_100(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        0.5125\n",
    "        + 0.2550 * mu\n",
    "        - 0.0079 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled test set shape: (950, 38)\n"
     ]
    }
   ],
   "source": [
    "# File patterns.\n",
    "train_files_pattern = \"/Users/abbaszal/Documents/Thesis_Project_Spambase/data/metadata/train_{i:02d}.csv\"\n",
    "test_files_pattern = \"/Users/abbaszal/Documents/Thesis_Project_Spambase/data/metadata/test_{i:02d}.csv\"\n",
    "\n",
    "# Concatenate all training files.\n",
    "df_train_global = pd.concat([\n",
    "    pd.read_csv(train_files_pattern.format(i=i)) for i in range(1, 11)\n",
    "]).dropna()\n",
    "\n",
    "# Concatenate all testing files.\n",
    "df_test_global = pd.concat([\n",
    "    pd.read_csv(test_files_pattern.format(i=i)) for i in range(1, 11)\n",
    "]).dropna()\n",
    "\n",
    "# Split features and labels.\n",
    "X_train_global = df_train_global.drop('act', axis=1)\n",
    "y_train_global = df_train_global['act']\n",
    "\n",
    "X_test_global = df_test_global.drop('act', axis=1)\n",
    "y_test_global = df_test_global['act']\n",
    "\n",
    "# Encode labels.\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_global = label_encoder.fit_transform(y_train_global)\n",
    "y_test_global = label_encoder.transform(y_test_global)\n",
    "\n",
    "# Scale features.\n",
    "scaler_global = StandardScaler()\n",
    "X_train_global_scaled = scaler_global.fit_transform(X_train_global)\n",
    "X_test_global_scaled  = scaler_global.transform(X_test_global)\n",
    "# Create a stratified subsample of the test set to speed up the runtime.\n",
    "subsample_size = 950  \n",
    "X_test_global_scaled, _, y_test_global, _ = train_test_split(\n",
    "    X_test_global_scaled, y_test_global,\n",
    "    train_size=subsample_size,\n",
    "    random_state=42,\n",
    "    stratify=y_test_global\n",
    ")\n",
    "print(\"Subsampled test set shape:\", X_test_global_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "eps               = 1e-8\n",
    "n_clients_list    = [10,20,30,40,50,60,70,80,90,100]\n",
    "n_trials          = 100\n",
    "base_random_seed  = 42\n",
    "max_depths        = [100]\n",
    "approach          = 'fedfor'\n",
    "\n",
    "# Saving directory\n",
    "save_dir = \"/Users/abbaszal/Documents/Fit/hugadb_fedfor_test\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "train_csv_path = \"/Users/abbaszal/Documents/Thesis_Project_Spambase/data/metadata/new_runs/train.csv\"\n",
    "df_full_train = pd.read_csv(train_csv_path).dropna(subset=['act']).reset_index(drop=True)\n",
    "\n",
    "for n_clients in n_clients_list:\n",
    "    print(f\"\\n> n_clients = {n_clients}\")\n",
    "          \n",
    "    # Dynamically get the corresponding payoff function\n",
    "    #payoff_func_name = f\"payoff_{n_clients}\"\n",
    "    #if payoff_func_name not in globals():\n",
    "        #raise ValueError(f\"Missing payoff function for {n_clients} clients\")\n",
    "    #payoff_func = globals()[payoff_func_name]\n",
    " \n",
    "\n",
    "    for max_depth in max_depths:\n",
    "        print(f\"\\n max_depth = {max_depth}\")\n",
    "\n",
    "        # reset counters for this config\n",
    "        counts_static = Counter()\n",
    "        lottery_count = 0\n",
    "\n",
    "        for trial in range(1, n_trials + 1):\n",
    "            \n",
    "            rand_component = random.randint(0, 500)\n",
    "            trial_seed = base_random_seed + trial + int(1000 * max_depth) + 2 * rand_component\n",
    "\n",
    "\n",
    "            df_trial, _ = train_test_split(\n",
    "                df_full_train,\n",
    "                train_size=10000,\n",
    "                random_state=trial_seed,\n",
    "                stratify=df_full_train['act']\n",
    "            )\n",
    "   \n",
    "            df_remaining = df_trial.copy()\n",
    "\n",
    "\n",
    "            client_partitions = []\n",
    "\n",
    "            sample_size = 3500 // n_clients\n",
    "            for client_idx in range(n_clients):\n",
    "                if len(df_remaining) < sample_size:\n",
    "                    raise ValueError(\"err\")\n",
    "\n",
    "                if len(df_remaining) == sample_size:\n",
    "                    df_client = df_remaining.copy()\n",
    "                    df_remaining = df_remaining.iloc[0:0] \n",
    "\n",
    "                else:\n",
    "                    df_client, df_remaining = train_test_split(\n",
    "                        df_remaining,\n",
    "                        train_size=sample_size,\n",
    "                        random_state=trial_seed,\n",
    "                        stratify=df_remaining['act']\n",
    "                    )\n",
    "                df_client = df_client.reset_index(drop=True)\n",
    "                client_partitions.append(df_client)\n",
    "\n",
    "            # train each client\n",
    "            client_models = []\n",
    "            client_global_accuracies   = {}\n",
    "\n",
    "            for client_idx, df_client in enumerate(client_partitions):\n",
    "\n",
    "                X_client = df_client.drop(columns=['act'])\n",
    "                y_client = df_client['act']\n",
    "\n",
    "                client_scaler = StandardScaler()\n",
    "                X_client_scaled = client_scaler.fit_transform(X_client)\n",
    "                y_client_encoded = label_encoder.transform(y_client)\n",
    "                # fit model\n",
    "                model = DecisionTree(\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=trial_seed\n",
    "                )\n",
    "                model.fit(X_client_scaled, y_client_encoded)\n",
    "                client_models.append(model)\n",
    "\n",
    "                # record its global-test accuracy\n",
    "                y_pred_global = model.predict(X_test_global_scaled)\n",
    "                acc_global = accuracy_score(y_test_global, y_pred_global)\n",
    "                client_global_accuracies[client_idx] = acc_global\n",
    "\n",
    "            # coalition evaluation\n",
    "            df_res = evaluate_coalitions2(\n",
    "                client_models=client_models,\n",
    "                client_global_accuracies=client_global_accuracies,\n",
    "                n_clients=n_clients,\n",
    "                aggregator_func=FederatedForest,\n",
    "                X_test=X_test_global_scaled,\n",
    "                y_test=y_test_global,\n",
    "                corrupt_client_indices=[],\n",
    "                approach=approach\n",
    "            )\n",
    "\n",
    "            # static窶身ame Nash counts\n",
    "            df_ne = find_nash_equilibria_v2(df_res)\n",
    "            if not df_ne.empty:\n",
    "                for coalition in df_ne.index:\n",
    "                    counts_static[coalition] += 1\n",
    "\n",
    "\n",
    "            # lottery窶身ame incentive check\n",
    "            vals      = np.array(list(client_global_accuracies.values()))\n",
    "            mu_full   = vals.mean()\n",
    "            sig_full  = vals.std(ddof=1)\n",
    "            payoff_f  = payoff_100(mu_full, sig_full)\n",
    "\n",
    "            has_incentive = any(\n",
    "                acc > payoff_f + eps\n",
    "                for acc in client_global_accuracies.values()\n",
    "            )\n",
    "            if not has_incentive:\n",
    "                lottery_count += 1\n",
    "\n",
    "\n",
    "        static_count = sum(counts_static.values())\n",
    "\n",
    "        counts_df = pd.DataFrame([{\n",
    "            'n_clients':           n_clients,\n",
    "            'max_iter':            max_depth,\n",
    "            'Static_Occurrences':  static_count,\n",
    "            'Lottery_Occurrences': lottery_count\n",
    "        }])\n",
    "        fname = (f\"Nash_Counts_{approach}\"\n",
    "                 f\"_nclients_{n_clients}\"\n",
    "                 f\"_maxiter_{max_depth}.csv\")\n",
    "        out_path = os.path.join(save_dir, fname)\n",
    "        counts_df.to_csv(out_path, index=False)\n",
    "        print(f\"saved {fname}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spambase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/abbaszal/Documents/Thesis_Project_Spambase/data/spambase.data'  # Adjust the path as needed\n",
    "df = pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def payoff_10(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.4315\n",
    "        + 0.0231 * mu\n",
    "        - 0.0085 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_20(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.4312\n",
    "        + 0.0180 * mu\n",
    "        + 0.0088 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_30(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.4131\n",
    "        + 0.0186 * mu\n",
    "        + 0.0111 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_40(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.3715\n",
    "        + 0.0121 * mu\n",
    "        + 0.0112 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_50(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.3369\n",
    "        + 0.0114 * mu\n",
    "        + 0.0058 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_60(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.3019\n",
    "        + 0.0244 * mu\n",
    "        + 0.0080 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_70(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.2800\n",
    "        + 0.0150 * mu\n",
    "        + 0.0093 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_80(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.2433\n",
    "        + 0.0138 * mu\n",
    "        + 0.0072 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_90(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.2230\n",
    "        + 0.0204 * mu\n",
    "        + 0.0040 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def payoff_100(mu: float, sigma: float) -> float:\n",
    "    z = (\n",
    "        2.1893\n",
    "        + 0.0150 * mu\n",
    "        + 0.0016 * sigma\n",
    "    )\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_fedfor(partitions, X_test, y_test, max_depth):\n",
    "    client_models = []\n",
    "    client_global_accuracies = {}\n",
    "    \n",
    "    for i, (X_i, y_i) in enumerate(partitions):\n",
    "        local_scaler = StandardScaler()\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, random_state=np.random.randint(0, 100000))\n",
    "        model.fit(local_scaler.fit_transform(X_i), y_i)\n",
    "        client_models.append(model)\n",
    "        y_pred = model.predict(X_test)\n",
    "        client_global_accuracies[i] = np.mean(y_pred == y_test)\n",
    "    return client_models, client_global_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed= 42\n",
    "X = df.iloc[:, :-1].to_numpy()\n",
    "y = df.iloc[:, -1].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "eps     = 1e-8\n",
    "n_clients_list    = [10,20,30,40,50,60,70,80,90,100]\n",
    "n_trials    = 100\n",
    "base_seed   = 42\n",
    "max_depths   = [ 100]\n",
    "approach    = 'fedfor'\n",
    "\n",
    "\n",
    "save_dir = (\n",
    "\"/Users/abbaszal/Documents/Fit/spambase_fedfor\"\n",
    ")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "all_results = [] \n",
    "\n",
    "\n",
    "for n_clients in n_clients_list:\n",
    "    print(f\"\\n> n_clients = {n_clients}\")\n",
    "          \n",
    "    # Dynamically get the corresponding payoff function\n",
    "    payoff_func_name = f\"payoff_{n_clients}\"\n",
    "    if payoff_func_name not in globals():\n",
    "        raise ValueError(f\"Missing payoff function for {n_clients} clients\")\n",
    "    payoff_func = globals()[payoff_func_name]\n",
    " \n",
    "\n",
    "    for max_depth in max_depths:\n",
    "        print(f\"\\n max_depth = {max_depth}\")\n",
    "        counts_static = Counter()\n",
    "        lottery_count = 0\n",
    "\n",
    "        for trial in range(1, n_trials+1):\n",
    "            rc = random.randint(0, 500)\n",
    "            trial_seed = base_seed + (trial-1) + 1000*max_depth + 2*rc\n",
    "            random.seed(trial_seed)\n",
    "            np.random.seed(trial_seed)\n",
    "\n",
    "            partitions = split_data_equal(\n",
    "                X_train, y_train,\n",
    "                n_clients=n_clients,\n",
    "                shuffle=True,\n",
    "                random_seed=trial_seed\n",
    "            )\n",
    "            client_models, client_accs = train_models_fedfor(\n",
    "                partitions=partitions,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                max_depth=max_depth\n",
    "            )\n",
    "\n",
    "            # coalition evaluation\n",
    "            df_res = evaluate_coalitions2(\n",
    "                client_models=client_models,\n",
    "                client_global_accuracies=client_accs,\n",
    "                n_clients=n_clients,\n",
    "                aggregator_func=FederatedForest,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                corrupt_client_indices=[],\n",
    "                approach=approach\n",
    "            )\n",
    "\n",
    "            # static窶身ame Nash counts\n",
    "            df_ne = find_nash_equilibria_v2(df_res)\n",
    "            if not df_ne.empty:\n",
    "                for coalition in df_ne.index:\n",
    "                    counts_static[coalition] += 1\n",
    "\n",
    "\n",
    "            # lottery窶身ame incentive check\n",
    "            vals = np.array(list(client_accs.values()))\n",
    "            mu_full   = vals.mean()\n",
    "            sig_full  = vals.std(ddof=1)\n",
    "            payoff_f  = payoff_func(mu_full, sig_full)\n",
    "\n",
    "            has_incentive = any(\n",
    "                acc > payoff_f \n",
    "                for acc in client_accs.values()\n",
    "            )\n",
    "            if not has_incentive:\n",
    "                lottery_count += 1\n",
    "\n",
    "        # aggregate counts into single numbers\n",
    "        static_count = sum(counts_static.values())\n",
    "\n",
    "\n",
    "        counts_df = pd.DataFrame([{\n",
    "            'n_clients':           n_clients,\n",
    "            'max_iter':            max_depth,\n",
    "            'Static_Occurrences':  static_count,\n",
    "            'Lottery_Occurrences': lottery_count\n",
    "        }])\n",
    "        fname = (f\"Nash_Counts_{approach}\"\n",
    "                    f\"_nclients_{n_clients}\"\n",
    "                    f\"_maxiter_{max_depth}.csv\")\n",
    "        out_path = os.path.join(save_dir, fname)\n",
    "        counts_df.to_csv(out_path, index=False)\n",
    "        print(f\" saved {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
